# -*- coding: utf-8 -*-
"""
Created on Wed Apr 29 10:09:28 2020

@author: jingr

Model plotting

"""
import os, sys
sys.path.append('./libs')
sys.path.append('./tool/libs')
sys.path.append('../')



import os, sys, re
sys.path.append(os.path.curdir)
sys.path.append(sys.argv[0])

helpDoc = '''
The predicting script for using built model. 

Usage :
If using all the default parameters, users could use a simple command line after modeling:
    
    python tool/layerPlot.py --paraFile tmpOut/parameters.txt --outFigFolder tmpOut

The '--paraFile' was the parameters generated by using running.py, and the --outFigFolder is to specify the output folder, in which a file named UMAP.pdf will be saved.

To use a certain n_neighbor and min_dist, the command becomes:
    
    python tool/layerPlot.py --paraFile tmpOut/parameters.txt --outFigFolder tmpOut --n_neighbors 10 --min_dist 0.3

To use the grid search for the two parameters, the command becomes:
    
    python tool/layerPlot.py --paraFile tmpOut/parameters.txt --outFigFolder tmpOut --grid_min_dist 0.01 0.2 0.02 --grid_n_neighbors 2 30 2

The "0.01 0.2 0.02" and "2 30 2" above will be passed to arange() in numpy (i.e. used as "start stop stepSize"), where min_dist will be set as float and n_neighbors as int.
Note that if '--grid_min_dist' or '--grid_n_neighbors' used, '--min_dist' or '--n_neighbors' will be ignored respectively.

If grid search used, the plots will be save in a pdf with multiple pages.

Currently, the layer ranked at the last 2 will be used for plotting, users could use --layerIndex to change it. But please note that not all the layer is able to be used, please see the jupyter notebook for more details.

Another selection for specify the layer is using --interactive 1 and following the questions to decide the layer name or index.

Sometimes users might be interesting with a high-dimensional output (such as the output from a 2D-CNN layer), this time the parameter “--interactive” is recommend for make the further operation, for example using:
	python tool/layerPlot.py --paraFile tmpOut/parameters.txt --interactive 1
or
	python tool/layerPlot.py --paraFile tmpOut/parameters.txt --interactive 1 --dimensionReduceMethod avg
will give users options for reducing the dimension of the output, users can split one dimension into slice and plot all (or just only one slice) of them, which would be used to figure out the performance of the output from different CNN filters. The parameter “--dimensionReduceMethod” might be necessary according to the option selected by users. The possible values of “--dimensionReduceMethod” are “min”, “max”, “avg” and “flatten”.

Please NOTE that if users choose to plot all slices of a dimension, the parameters for grid plotting will be ignored since the calculation will be too large.



To change the color, please use --theme or the --color_key_cmap and --background. NOTE that if --theme used, the --color_key_cmap and --background will not used for plotting.
options available for --theme:        
       * 'blue'
       * 'red'
       * 'green'
       * 'inferno'
       * 'fire'
       * 'viridis'
       * 'darkblue'
       * 'darkred'
       * 'darkgreen'
The parameter for --color_key_cmap is following matplotlib, please see https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html for details.
The parameter for --background could be a simple 'black' or 'white', but could be other color obeying the rule of matplotlib.

NOTE: This script is to plot the model layers using UMAP, currently only n_neighbor and min_dist are able to be modified, if users want to use more features of UMAP or integrate this script into other work, please use our jupyter notebook (in the folder "notebook") as a template.
'''
import paraParser
if '--help' in sys.argv:
    print(helpDoc)
    exit()

import moduleRead
import dataProcess
#import analysisPlot
import numpy as np
#from sklearn.metrics import accuracy_score,f1_score,roc_auc_score,recall_score,precision_score,confusion_matrix,matthews_corrcoef 
import tensorflow as tf
from utils import TextDecorate, evalStrList

from keras.models import Model
from keras.models import Sequential
import umap
import umap.plot
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
td = TextDecorate()


defaultParaDict, numSet, intSet, boolSet, objSet = paraParser.getDefaultParameters()
defaultParaDict['grid_n_neighbors'] = []
defaultParaDict['grid_min_dist'] = []
defaultParaDict['n_neighbors'] = 15
defaultParaDict['min_dist'] = 0.1
defaultParaDict['layerIndex'] = -2
defaultParaDict['figWidth'] = 800
defaultParaDict['figHeight'] = 800
defaultParaDict['outFigFolder'] = None
defaultParaDict['metric'] = 'euclidean'
defaultParaDict['color_key_cmap'] = 'rainbow'
defaultParaDict['background'] = 'white'
defaultParaDict['theme'] = None
defaultParaDict['color_key_cmap'] = 'rainbow'
defaultParaDict['background'] = 'white'
defaultParaDict['interactive'] = False
defaultParaDict['dimensionReduceMethod'] = 'max'


#numSet.add('grid_min_dist')
#intSet.add('grid_n_neighbors')
numSet.add('min_dist')
intSet.add('n_neighbors')
intSet.add('layerIndex')
intSet.add('figWidth')
intSet.add('figHeight')
boolSet.add('interactive')

paraDictCMD = paraParser.parseParameters(sys.argv[1:],defaultParaTuple=(defaultParaDict, numSet, intSet, boolSet, objSet))
paraFile = paraDictCMD['paraFile']
paraDict = paraParser.parseParametersFromFile(paraFile,defaultParaTuple=(paraDictCMD, numSet, intSet, boolSet, objSet))

paraDict['dataTestFilePaths'] = paraDict['dataTrainFilePaths']
paraDict['dataTestModelInd'] = paraDict['dataTrainModelInd']
paraDict['dataTestLabel'] = paraDict['dataTrainLabel']

dimensionReduceMethod = paraDict['dimensionReduceMethod']
if not (dimensionReduceMethod == 'max' or dimensionReduceMethod == 'avg' or dimensionReduceMethod == 'min' or dimensionReduceMethod == 'flatten'):
    td.printC('dimensionReduceMethod should be "max", "avg", "min" or "flatten"','r')
    exit()
#parameters

grid_n_neighbors = paraDict['grid_n_neighbors']
if len(grid_n_neighbors) > 0:
    grid_n_neighbors = evalStrList(grid_n_neighbors)
grid_min_dist = paraDict['grid_min_dist']
if len(grid_min_dist) > 0:
    grid_min_dist = evalStrList(grid_min_dist)
layerIndex = paraDict['layerIndex']
figWidth = paraDict['figWidth']
figHeight = paraDict['figHeight']
outFigPath = paraDict['outFigFolder']
if outFigPath is None:
    outFigPath = paraDict['outSaveFolderPath']

#dataType = paraDict['dataType']
dataTypeList = paraDict['dataType']
dataEncodingType = paraDict['dataEncodingType']
spcLen = paraDict['spcLen']
firstKernelSize = paraDict['firstKernelSize']
#dataTrainFilePaths = paraDict['dataTrainFilePaths']
#dataTrainLabel = paraDict['dataTrainLabel']
dataTestFilePaths = paraDict['dataTestFilePaths']
dataTestLabel = paraDict['dataTestLabel']
#modelLoadFile = paraDict['modelLoadFile']
#weightLoadFile = paraDict['weightLoadFile']
dataSplitScale = paraDict['dataSplitScale']
outSaveFolderPath = paraDict['outSaveFolderPath']
showFig = paraDict['showFig']
saveFig = paraDict['saveFig']
savePrediction = paraDict['savePrediction']

interactive = paraDict['interactive']

loss = paraDict['loss']
optimizer = paraDict['optimizer']
if not optimizer.startswith('optimizers.'):
    optimizer = 'optimizers.' + optimizer
if not optimizer.endswith('()'):
    optimizer = optimizer + '()'
metrics = paraDict['metrics']

shuffleDataTrain = paraDict['shuffleDataTrain']
shuffleDataTest = paraDict['shuffleDataTest']
batch_size = paraDict['batch_size']
epochs = paraDict['epochs']

#useKMer = paraDict['useKMer']
#KMerNum = paraDict['KMerNum']
inputLength = paraDict['inputLength']
modelSaveName = paraDict['modelSaveName']
weightSaveName = paraDict['weightSaveName']
noGPU = paraDict['noGPU']
labelToMat = paraDict['labelToMat']


modelLoadFile = paraDict['modelLoadFile']
useKMerList = paraDict['useKMer']
if len(useKMerList ) == 0:
    useKMerList = [False] * len(modelLoadFile)
KMerNumList = paraDict['KMerNum']
if len(KMerNumList ) == 0:
    KMerNumList = [3] * len(modelLoadFile)
    
#dataTrainModelInd = paraDict['dataTrainModelInd']
#if len(modelLoadFile) == 1:
#    dataTrainModelInd = [0] * len(dataTrainFilePaths)
dataTestModelInd = paraDict['dataTestModelInd']
if len(modelLoadFile) == 1:
    dataTestModelInd = [0] * len(dataTestFilePaths)

modelPredictFile = outSaveFolderPath + os.path.sep + modelSaveName
weightLoadFile = outSaveFolderPath + os.path.sep + weightSaveName
#modelPredictFile = 'D:/workspace/autoBioSeqpy/tmpOut/tmpMod.json'
#weightLoadFile = 'D:/workspace/autoBioSeqpy/tmpOut/tmpWeight.bin'

if not os.path.exists(modelPredictFile):
    if os.path.exists('../'+modelPredictFile):
        os.chdir('../')
    else:
        td.printC('the model load file %s is unavailable, please check the path.' %modelPredictFile,'r')

model = moduleRead.readModelFromJsonFileDirectly(modelPredictFile,weightLoadFile)

    
def unBoundLayers(modelIn,layers = []):
    for layer in modelIn.layers:
        if not 'sequential' in layer.name.lower():
            layers.append(layer)
        else:
            unBoundLayers(layer,layers)
    return layers

def generateNewModelFromLayers(layers):
    newModel = Sequential()
    for layer in layers:
        newModel.add(layer)
    return newModel

def genrerateNewModelFromModel(oriModel, selectedLayerIndex = -2, td = td, interactive=False):
    isConcatenate, hasSequential, avaiLayerIndex = analAvaiLayers(oriModel)
    # print(selectedLayerIndex)
    layerIndexFix = selectedLayerIndex
    if layerIndexFix < 0:
        layerIndexFix = layerIndexFix + len(avaiLayerIndex)
    if layerIndexFix < 0 or layerIndexFix > len(avaiLayerIndex) - 1:
        td.printC('Only %d layers could be used to generating UMAP, but the index %d is out of the range.' %(len(analAvaiLayers),selectedLayerIndex),'r')
    
    if interactive:
        td.printC('Since interactive is set as True, few operations will be decided by users:','b')
        if hasSequential:
            td.printC('A sequential model detected in the current model, the index model is suggested.','p')
        useName = input('Using index (e.g. an integer such as 0,1,2,...) or the name printed above?\n0 for index and 1 for name:')
        while not (useName == '0' or useName == '1'):
            useName = input('type 0 or 1:')
        if useName == '1':
            td.printC('The names of the layers:','b')
            for layer in oriModel.layers:
                td.printC(layer.name,'B')
            layerName = input('Please provide the layer name:')
            newModel = Model(inputs=oriModel.input,outputs=oriModel.get_layer(layerName).output)
        else:
            td.printC('The names and indexes of the layers:','b')
            upackedLayers = unBoundLayers(oriModel)
            for i,layer in enumerate(upackedLayers):
                td.printC('%d: %s' %(i,layer.name), 'B')
            layerIndex = input('Please provide the layer index:')
            layerIndex = int(layerIndex)
            newModel = generateNewModelFromLayers(upackedLayers[:layerIndex+1])
    else:
        if isConcatenate:
            newModel = Model(inputs=oriModel.input,outputs=oriModel.layers[avaiLayerIndex[selectedLayerIndex]].output)
        else:
            if hasSequential:
                upackedLayers = unBoundLayers(oriModel)
                newModel = generateNewModelFromLayers(upackedLayers[:selectedLayerIndex+1])
            else:
                newModel=Model(inputs=oriModel.input,outputs=oriModel.layers[avaiLayerIndex[selectedLayerIndex]].output)
    return newModel

def analAvaiLayers(modelIn):
    isConcatenate = False
    hasSequential = False
    lastConcatenateLayerNum = None
    for i,layer in enumerate(modelIn.layers):
        if 'concatenate' in layer.name.lower():
            isConcatenate = True
            lastConcatenateLayerNum = i
        if 'sequential' in layer.name.lower():
            hasSequential = True
    avaiLayerIndex = []
    if isConcatenate:
        avaiLayerIndex = range(lastConcatenateLayerNum,len(modelIn.layers))
    else:
        avaiLayerIndex = range(len(modelIn.layers))
    return isConcatenate, hasSequential, list(avaiLayerIndex)

def plotOneUMAP(outName, testLabelArr, predicted_Probability, plotDict, featureDict = None, pdf=None, td=td, subTitle = None):
    if featureDict is None:
        mapper = umap.UMAP().fit(predicted_Probability)
    else:
        mapper = umap.UMAP(**featureDict).fit(predicted_Probability)
    plotObj = umap.plot.points(mapper, labels=testLabelArr, **plotDict)

    if pdf is None:        
        plt.savefig(outName)
        td.printC('%s saved.' %(outName), 'g')
    else:
        if subTitle is None:
            subTitle = re.findall('(NNeighbor.+)\.pdf',outName)[0]
        plt.title(subTitle)
#        pdf.savefig(fig)
        pdf.savefig()
        td.printC('%s plotted.' %(subTitle), 'b')

    plt.clf()
    plt.close('all')
    
def dimensionReduction(matIn, keepDim, dimensionReduceMethod):
    tmpMat = matIn.copy()
    if dimensionReduceMethod == 'flatten':
        tmpMat = tmpMat.reshape([tmpMat.shape[0], np.prod(tmpMat.shape[1:])])
    else:
        tmpMethod = None
        if dimensionReduceMethod == 'max':
            tmpMethod = np.max
        elif dimensionReduceMethod == 'min':
            tmpMethod = np.min
        elif dimensionReduceMethod == 'avg':
            tmpMethod = np.mean
        while len(tmpMat.shape) > 2:
            recDim = len(tmpMat.shape) - 1
            if recDim == keepDim:
                recDim -= 1
                keepDim -= 1
            tmpMat = tmpMethod(tmpMat,axis = recDim)
    return tmpMat
    
    
verbose = paraDict['verbose']

predictionSavePath = None
for i,k in enumerate(sys.argv):
    if k == '--predictionSavePath':
        predictionSavePath = sys.argv[i+1]
    elif k == '--verbose':
        verbose = sys.argv[i+1]

colorText = paraDict['colorText']
if colorText.lower() == 'auto':
    import platform
    if 'win' in platform.system().lower():
        td.disable()
elif not bool(eval(colorText)):
    td.disable()
    
if noGPU:
    if verbose:
        td.printC('As set by user, gpu will be disabled.','g')
    os.environ["CUDA_VISIBLE_DEVICES"] = '-1'
else:
    #check the version of tensorflow before configuration
    tfVersion = tf.__version__
    if int(tfVersion.split('.')[0]) >= 2:
#        config = tf.compat.v1.ConfigProto(allow_growth=True)
        config = tf.compat.v1.ConfigProto()
        config.gpu_options.allow_growth = True

        sess =tf.compat.v1.Session(config=config)
    else:
        config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))
        sess = tf.Session(config=config)


if not len(dataTypeList) == len(modelLoadFile):
    if verbose:
        td.printC('Please provide enough data type(s) as the number of --modelLoadFile','r')
assert len(dataTypeList) == len(modelLoadFile)

featureGenerators = []
for i,subDataType in enumerate(dataTypeList):
    if subDataType.lower() == 'protein':
        if verbose:
            td.printC('Enconding protein data for model %d ...' %i,'b')
        featureGenerator = dataProcess.ProteinFeatureGenerator(dataEncodingType[i], useKMer=useKMerList[i], KMerNum=KMerNumList[i])
    elif subDataType.lower() == 'dna':
        if verbose:
            td.printC('Enconding DNA data for model %d ...' %i,'b')
        featureGenerator = dataProcess.DNAFeatureGenerator(dataEncodingType[i], useKMer=useKMerList[i], KMerNum=KMerNumList[i])
    elif subDataType.lower() == 'rna':
        if verbose:
            td.printC('Enconding RNA data for model %d ...' %i,'b')
        featureGenerator = dataProcess.RNAFeatureGenerator(dataEncodingType[i], useKMer=useKMerList[i], KMerNum=KMerNumList[i])
    elif subDataType.lower() == 'other':
        if verbose:
            td.printC('Reading CSV-like data for model %d ...' %i,'b')
        featureGenerator = dataProcess.OtherFeatureGenerator()
    elif subDataType.lower() == 'smiles':
	if verbose:
	    td.printC('Enconding Smiles data for model %d ...' %i,'b')
	featureGenerator = dataProcess.SmilesFeatureGenerator(dataEncodingType[i], useKMer=useKMerList[i], KMerNum=KMerNumList[i])
    else:
        td.printC('Unknow dataType %r, please use \'protein\', \'dna\' ,\'rna\' or \'other\'' %subDataType, 'r')
    featureGenerators.append(featureGenerator)
    assert subDataType.lower() in ['protein','dna','rna','smiles','other']


if verbose:
    td.printC('Checking the number of test files, which should be larger than 1 (e.g. at least two labels)...','b')
assert len(dataTestFilePaths) > 0

if verbose:
    td.printC('Begin to generate test dataset...','b')

testDataLoadDict = {}    
for modelIndex in range(len(modelLoadFile)):
    testDataLoadDict[modelIndex] = []
#    testDataLoaders = []
for i,dataPath in enumerate(dataTestFilePaths):
    modelIndex = dataTestModelInd[i]
    featureGenerator = featureGenerators[modelIndex]
    dataLoader = dataProcess.DataLoader(label = dataTestLabel[i], featureGenerator=featureGenerator)
    dataLoader.readFile(dataPath, spcLen = spcLen[modelIndex])
    testDataLoadDict[modelIndex].append(dataLoader)

testDataMats = []
testLabelArrs = []
testNameLists = []
for modelIndex in range(len(modelLoadFile)):
    testDataLoaders = testDataLoadDict[modelIndex]
    testDataSetCreator = dataProcess.DataSetCreator(testDataLoaders)
    testDataMat, testLabelArr, nameList = testDataSetCreator.getDataSet(toShuffle=False, withNameList=True)
    testDataMats.append(testDataMat)
    testLabelArrs.append(testLabelArr)
    testNameLists.append(nameList)
if verbose:
    td.printC('Test datasets generated.','g')
nameTemp = testNameLists[0]    
testDataMats, testLabelArrs, sortedIndexes = dataProcess.matAlignByName(testDataMats,nameTemp,testLabelArrs,testNameLists)
testNameLists = [nameTemp] * len(testNameLists)
    
tmpTempLabel = testLabelArrs[0]
for tmpLabel in testLabelArrs:
    assert np.sum(np.array(tmpTempLabel) - np.array(tmpLabel)) == 0   


if labelToMat:
    if verbose:
        td.printC('Since labelToMat is set, the labels would be changed to onehot-like matrix','g')
    testLabelArr,testLabelArrDict,testArrLabelDict = dataProcess.labelToMat(testLabelArrs[0])
#    print(testLabelArr)
else:
    testLabelArr = testLabelArrs[0]

if len(testLabelArr.shape) == 2:
    testLabelArr = np.argmax(testLabelArr, axis=-1)
    
if verbose:
#    print('Datasets generated, the scales are:\n\ttraining: %d x %d\n\ttest: %d x %d' %(trainDataMat.shape[0],trainDataMat.shape[1],testDataMat.shape[0],testDataMat.shape[1]))    
    td.printC('begin to prepare model...','b')
#    print('Loading keras model from .py files...')
    
if verbose:
    td.printC('Checking module file for modeling','b')
if modelPredictFile is None:
    if verbose:
        td.printC('please provide a model file in a json file.','r')
if weightLoadFile is None:
    if verbose:
        td.printC('the weight file is necessary for predicting, otherwise the model will be with initialized weight','r')
assert not modelPredictFile is None
assert not weightLoadFile is None

if verbose:
    td.printC('Loading module and weight file','b')
model = moduleRead.readModelFromJsonFileDirectly(modelPredictFile,weightLoadFile)
if verbose:
    td.printC('Module loaded, generating the summary of the module','b')
    model.summary()

'''
if not outSaveFolderPath is None:
    if not os.path.exists(outSaveFolderPath):        
        os.makedirs(outSaveFolderPath, exist_ok=True)
    else:
        if verbose:
            td.printC('outpath %s is exists, the outputs might be overwirten' %outSaveFolderPath,'p')


predicted_Probability = model.predict(testDataMats)
if not 'predict_classes' in dir(model):
    prediction = np.rint(predicted_Probability)
#    if labelToMat:
#        prediction = dataProcess.matToLabel(np.array(prediction,dtype=int), testArrLabelDict,td=td)
else:
    prediction = model.predict_classes(testDataMats)
'''
#############################################################################################################
#############################################################################################################
#############################################################################################################
#############################################################################################################
#############################################################################################################
#############################################################################################################
if not outFigPath is None:
    if not os.path.exists(outFigPath):        
        os.makedirs(outFigPath, exist_ok=True)
#    else:
#        if verbose:
#            td.printC('outpath %s is exists, the outputs might be overwirten' %outSaveFolderPath,'p')    



#upackedLayers = unBoundLayers(model)
#upackedModel = generateNewModelFromLayers(upackedLayers[:-4])
#upackedModel.summary()
oriPrediction = model.predict(testDataMats)
newModel = genrerateNewModelFromModel(model,selectedLayerIndex=layerIndex, td=td, interactive=interactive)
td.printC('The model for plotting is:','b')
newModel.summary()
predicted_Probability = newModel.predict(testDataMats)

while len(predicted_Probability.shape) > 2:
    td.printC('The output from the current model contain high dimensione, currently is %s' %(str(predicted_Probability.shape[1:])),'b')
    if interactive:
        drSelect = input('How to make the dimensional reduction?\n"0" to select one slice in a dimension, \n"1" for all slices of a dimension, \n"2" for dimensional reduction directly (using %s, could be changed by changing --dimensionReduceMethod) \nPlease select the number:' %(dimensionReduceMethod))
        while not (drSelect == '0' or drSelect == '1' or drSelect == '2' ):
            drSelect = input('type 0 or 1 or 2:')
        if drSelect == '0':
            tmpShape = predicted_Probability.shape[1:]
            tmpStr = 'Which demension you whould like to used for spliting? Currently the shape is %s and thus\n' %(str(tmpShape))
            for i,s in enumerate(tmpShape):
                tmpStr += 'select "%d" for the dim of "%d" which means pick one slice in %d for visualization,\n' %(i,s,s)
            tmpStr = tmpStr + 'please select the number:'
            splitDimension = input(tmpStr)
            while int(splitDimension) >= len(tmpShape):
                splitDimension = input('Please type an integer less than %d:' %(len(tmpShape)))
            tmpStr = 'Please select a number less than %d for extracting the data:' %(tmpShape[int(splitDimension)])
            kernelNum = input(tmpStr)
            while int(kernelNum) >=  tmpShape[int(splitDimension)]:
                kernelNum = input('Please type an integer less than %d:' %(tmpShape[int(splitDimension)]))
            splitDimension = int(splitDimension) + 1
            kernelNum = int(kernelNum)
            tmpCMD = 'predicted_Probability['
            for i,s in enumerate(predicted_Probability.shape):
                if i == splitDimension:
                    tmpCMD += '%d,' %(kernelNum)
                else:
                    tmpCMD += ':,'
            tmpCMD = tmpCMD[:-1] + ']'
            predicted_Probability = eval(tmpCMD)
            td.printC('The shape of the slice is: %s' %(predicted_Probability.shape[1:]), 'b')
        elif drSelect == '1':
            tmpShape = predicted_Probability.shape[1:]
            tmpStr = 'Which demension you whould like to used for spliting? Currently the shape is %s and thus\n' %(str(tmpShape))
            for i,s in enumerate(tmpShape):
                tmpStr += 'select "%d" for the dim of "%d" which means generate %d slices of plotting,\n' %(i,s,s)
            tmpStr = tmpStr + 'please select the number:'
            splitDimension = input(tmpStr)
            while int(splitDimension) >= len(tmpShape):
                splitDimension = input('Please type an integer less than %d:' %(len(tmpShape)))
            splitDimension = int(splitDimension) + 1
            reducedShape = list(tmpShape[:splitDimension-1]) + list(tmpShape[splitDimension:])
            keepDimension = None
            if len(reducedShape) > 1:
                td.printC('The shape of the slices is %s, which is still larger than 1' %(str(reducedShape)), 'b')
                tmpStr = 'Which demension you whould like to keep? Currently the shape is %s and thus' %(str(reducedShape))
                for i,s in enumerate(reducedShape):
                    tmpStr += ' %d for "%d",' %(i,s)
                tmpStr = tmpStr[:-1] + ':'
                keepDimension = input(tmpStr)
                while int(keepDimension) >= len(reducedShape):
                    keepDimension = input('Please type an integer less than %d:' %(len(reducedShape)))
                keepDimension = int(keepDimension) + 1
#            if keepDimension >= splitDimension:
#                keepDimension += 1
            td.printC('Start to generate the UMAP figures, please note that the parameter for grid will be ignored in this case.','p')
            #######################parameters for the sub-loop
            n_neighbors = paraDict['n_neighbors']
            featureDict={
                    'n_neighbors' : None,
                    'min_dist' : None,
                    'metric' : defaultParaDict['metric'],
                    }
            
            plotDict = {}
            if not paraDict['theme'] is None:
                plotDict['theme'] = paraDict['theme']
            else:
                plotDict['color_key_cmap'] = paraDict['color_key_cmap']
                plotDict['background'] = paraDict['background']
            featureDict['n_neighbors'] = n_neighbors
            min_dist = paraDict['min_dist']
            featureDict['min_dist'] = min_dist
            pdf = PdfPages('%s/UMAP.pdf' %outFigPath)
            outName = '%s/UMAP.pdf' %(outFigPath) #not used!
            ##################################################
            for kernelNum in range(predicted_Probability.shape[splitDimension]):
                tmpCMD = 'predicted_Probability['
                for i,s in enumerate(predicted_Probability.shape):
                    if i == splitDimension:
                        tmpCMD += '%d,' %(kernelNum)
                    else:
                        tmpCMD += ':,'
                tmpCMD = tmpCMD[:-1] + ']'
                subData = eval(tmpCMD)
#                print(subData.shape)
                if not keepDimension is None:
                    subData = dimensionReduction(subData, keepDimension, dimensionReduceMethod)
#                print(np.sum(subData))
                subTitle = 'SubDimNum: %d/%d' %(kernelNum,predicted_Probability.shape[splitDimension]-1)
                plotOneUMAP(outName, testLabelArr, subData, plotDict, featureDict = featureDict, pdf=pdf, td=td, subTitle=subTitle)
            pdf.close()
            if verbose:
                td.printC('%s/UMAP.pdf saved.' %outFigPath, 'g')
            exit()
        elif drSelect == '2':
            tmpShape = predicted_Probability.shape[1:]
            tmpStr = 'Which demension you whould like to keep? Currently the shape is %s and thus' %(str(tmpShape))
            for i,s in enumerate(tmpShape):
                tmpStr += ' %d for %d,' %(i,s)
            tmpStr = tmpStr[:-1] + ':'
            keepDimension = input(tmpStr)
            while int(keepDimension) >= len(tmpShape):
                keepDimension = input('Please type an integer less than %d:' %(len(tmpShape)))
            keepDimension = int(keepDimension) + 1
            predicted_Probability = dimensionReduction(predicted_Probability, keepDimension, dimensionReduceMethod)
    else:
        td.printC('Since the --interactive is not used, the last dimension will be kept, please use --interactive for more options.')
        predicted_Probability = dimensionReduction(predicted_Probability, len(predicted_Probability.shape) - 1, dimensionReduceMethod)
        

if len(grid_min_dist) > 0 or len(grid_n_neighbors) > 0:
    pdf = PdfPages('%s/UMAP.pdf' %outFigPath)
    
featureDict={
        'n_neighbors' : None,
        'min_dist' : None,
        'metric' : defaultParaDict['metric'],
        }

plotDict = {}
if not paraDict['theme'] is None:
    plotDict['theme'] = paraDict['theme']
else:
    plotDict['color_key_cmap'] = paraDict['color_key_cmap']
    plotDict['background'] = paraDict['background']

#print(grid_n_neighbors)
if verbose:
    td.printC('Started to generating UMAP...', 'b')
    
#if len(testLabelArr.shape) == 2:
#    testLabelArr = np.argmax(testLabelArr, axis=-1)

if len(grid_min_dist) > 0 and len(grid_n_neighbors) > 0:
    for min_dist in np.arange(*grid_min_dist):
        featureDict['min_dist'] = min_dist
        for n_neighbors in np.arange(*grid_n_neighbors).astype(int):
            featureDict['n_neighbors'] = n_neighbors
            outName = '%s/UMAP_NNeighbor_%s_MDist_%s.pdf' %(outFigPath,str(n_neighbors),str(min_dist))
#            print(outName)
            plotOneUMAP(outName, testLabelArr, predicted_Probability, plotDict, featureDict = featureDict, pdf=pdf, td=td)
elif len(grid_min_dist) > 0:
    n_neighbors = paraDict['n_neighbors']
    featureDict['n_neighbors'] = n_neighbors
    for min_dist in np.arange(*grid_min_dist):
        featureDict['min_dist'] = min_dist
        outName = '%s/UMAP_NNeighbor_%s_MDist_%s.pdf' %(outFigPath,str(n_neighbors),str(min_dist))
        plotOneUMAP(outName, testLabelArr, predicted_Probability, plotDict, featureDict = featureDict, pdf=pdf, td=td)
elif len(grid_n_neighbors) > 0:
    min_dist = paraDict['min_dist']
    featureDict['min_dist'] = min_dist
    for n_neighbors in np.arange(*grid_n_neighbors).astype(int):
        featureDict['n_neighbors'] = n_neighbors
        outName = '%s/UMAP_NNeighbor_%s_MDist_%s.pdf' %(outFigPath,str(n_neighbors),str(min_dist))
        plotOneUMAP(outName, testLabelArr, predicted_Probability, plotDict, featureDict = featureDict, pdf=pdf, td=td)
else:
    n_neighbors = paraDict['n_neighbors']
    featureDict['n_neighbors'] = n_neighbors
    min_dist = paraDict['min_dist']
    featureDict['min_dist'] = min_dist
    outName = '%s/UMAP.pdf' %(outFigPath)
    plotOneUMAP(outName, testLabelArr, predicted_Probability, plotDict, featureDict = featureDict, td=td)


if len(grid_min_dist) > 0 or len(grid_n_neighbors) > 0:
    pdf.close()
    if verbose:
        td.printC('%s/UMAP.pdf saved.' %outFigPath, 'g')
